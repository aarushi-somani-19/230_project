---
title: "Untitled"
output: html_document
date: "2024-04-27"
---
# Ridge and Lasso 
```{r}
library(glmnet)
library(data.table)

# Data Preparation
# Convert character columns to numeric
cols_to_convert <- c("emp_incq1", "emp_incq2", "emp_incq3", "emp_incq4")
for (col in cols_to_convert) {
  emp_aff_math_biz[[col]] <- as.numeric(as.character(emp_aff_math_biz[[col]]))
}

# Selecting predictors
more_predictors <- c("spend_aap", "spend_acf", "spend_aer", "spend_apg", "spend_durables", "spend_nondurables", "merchants_professional", "merchants_health", "merchants_food_accommodation", "merchants_other_services", "merchants_retail", "NE", "W", "MW", "S", "wave1", "wave2")
predictors <- c("emp", "spend_all", cols_to_convert, more_predictors)
setDT(emp_aff_math_biz)

# Replace "." with NA in only the predictor columns
emp_aff_math_biz[, (predictors) := lapply(.SD, function(x) as.numeric(replace(x, x == ".", NA))), 
                 .SDcols = predictors]
emp_aff_math_biz_clean <- na.omit(emp_aff_math_biz[, c("revenue_all", predictors), with = FALSE])
```


```{r}
# Create matrices for regression
x <- as.matrix(emp_aff_math_biz_clean[, ..predictors])
y <- emp_aff_math_biz_clean$revenue_all

# Set seed for reproducibility
#set.seed(60)

# Fit the ridge regression model
ridge_model <- glmnet(x, y, alpha = 0)

# Cross-validation for optimal lambda
cv_ridge <- cv.glmnet(x, y, alpha = 0)
plot(cv_ridge)
best_lambda <- cv_ridge$lambda.min

# Plotting Bias-Variance Tradeoff
lambda_seq <- seq(0, max(cv_ridge$lambda), length.out = 100)
bias_seq <- variance_seq <- mse_seq <- rep(0, length(lambda_seq))

for (i in seq_along(lambda_seq)) {
  ll <- lambda_seq[i]
  fit <- glmnet(x, y, alpha = 0, lambda = ll)
  pred <- predict(fit, s = ll, newx = x)
  bias_seq[i] <- mean((y - mean(y))^2)  # Theoretical bias, for demonstration
  variance_seq[i] <- var(pred)
  mse_seq[i] <- mean((y - pred)^2)
}

plot(lambda_seq, bias_seq, type = "l", col = "red", ylim = c(min(c(bias_seq, variance_seq, mse_seq)), max(c(bias_seq, variance_seq, mse_seq))), xlab = "Lambda", ylab = "Metric Value", main = "Bias-Variance Tradeoff")
lines(lambda_seq, variance_seq, col = "blue")
lines(lambda_seq, mse_seq, col = "green")
legend("topright", legend = c("Bias^2", "Variance", "MSE"), col = c("red", "blue", "green"), lty = 1)
best_lambda
```

First Plot
Error Path: The plot shows cross-validation process used to select the optimal regularization parameter (lambda) for ridge regression. The x-axis represents the log-transformed lambda values, while the y-axis represents the mean squared error (MSE) for each value of lambda. The plot's trend shows how the model's prediction error changes as the regularization strength varies.

# Ch 15 (ols, ridge, lasso)

# MSE comparisons

```{r}
# OLS

# Split the data into training and test sets
set.seed(230)  # For reproducibility
nsample <- nrow(emp_aff_math_biz_clean)
trainindex <- sample(1:nsample, floor(nsample * 0.9))
testindex <- (1:nsample)[-trainindex]

# Define the response variable
yvector <- emp_aff_math_biz_clean$revenue_all

# Prepare the model matrix excluding the response variable
xmatrix <- model.matrix(~ . - emp_aff_math_biz_clean$revenue_all, data = emp_aff_math_biz_clean)[trainindex, ]

# Fit the linear model using the training set
ols_lm <- lm(yvector[trainindex] ~ xmatrix)

# Define the response variable and predictors for training and testing
y_train <- emp_aff_math_biz_clean$revenue_all[trainindex]
y_test <- emp_aff_math_biz_clean$revenue_all[testindex]
x_train <- model.matrix(~ . - revenue_all, data = emp_aff_math_biz_clean)[trainindex, ]
x_test <- model.matrix(~ . - revenue_all, data = emp_aff_math_biz_clean)[testindex, ]

# Calculate prediction error and MSE using the test set
y_test <- yvector[testindex]
predictions_ols <- predict(ols_lm, newdata = list(x_train = x_test))
mse_ols <- mean((y_test - predictions_ols)^2)

# Ridge and Lasso

# Ridge regression using glmnet (uses cross-validation to find optimal lambda)
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0)  # alpha=0 for ridge regression
optimal_lambda_ridge <- cv_ridge$lambda.min
ridge_model <- glmnet(x_train, y_train, alpha = 0, lambda = optimal_lambda_ridge)

# Make predictions using the ridge regression model on the testing set
predictions_ridge <- predict(ridge_model, s = optimal_lambda_ridge, newx = x_test)
mse_ridge <- mean((y_test - predictions_ridge)^2)

# Lasso regression using glmnet (also uses cross-validation to find optimal lambda)
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1)  # alpha=1 for lasso regression
optimal_lambda_lasso <- cv_lasso$lambda.min
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = optimal_lambda_lasso)

# Make predictions using the lasso regression model on the testing set
predictions_lasso <- predict(lasso_model, s = optimal_lambda_lasso, newx = x_test)
mse_lasso <- mean((y_test - predictions_lasso)^2)

# Output the MSE for both OLS, ridge, lasso
list(mse_ols = mse_ols, mse_ridge = mse_ridge, mse_lasso = mse_lasso)
```

```{r}
# Extract coefficients at the optimal lambda
coefficients_lasso <- coef(lasso_model, s = optimal_lambda_lasso)
# Convert to a more readable format, removing zero coefficients
significant_coefficients <- coefficients_lasso[coefficients_lasso != 0]

# Print the significant predictors along with their names
if (is.matrix(x_train)) {
  predictor_names <- colnames(x_train)
} else {
  predictor_names <- names(x_train)
}

# Combine names with coefficients
significant_predictors <- data.frame(
  Predictor = predictor_names,
  Coefficient = as.numeric(significant_coefficients)  # Excludes the intercept
)

print(significant_predictors)
```



```{r}
# Plot MSE's
# Create a data frame for plotting
mse_data <- data.frame(
  Model = c("OLS", "Ridge", "Lasso"),
  MSE = c(mse_ols, mse_ridge, mse_lasso)
)

# Plot the data
mse_plot <- ggplot(mse_data, aes(x = Model, y = MSE, fill = Model)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_brewer(palette = "Pastel1") +
  labs(title = "Comparison of Model MSE", x = "Model", y = "Mean Squared Error (MSE)") +
  theme_minimal()

# Display the plot
print(mse_plot)
```
Lasso Regression (pink bar) has the lowest MSE, indicating that among the three models, it has the best performance in terms of prediction accuracy on the test data.
OLS Regression (blue bar) has the highest MSE, suggesting that it may be overfitting the data or not adequately capturing the underlying structure compared to the regularized models.
Ridge Regression (green bar) performs better than OLS but slightly worse than Lasso in this instance.

```{r}
# For Lasso, glmnet does not provide AIC/BIC directly, you'll need R-squared and could calculate AIC or BIC manually if necessary
lasso_pred <- predict(lasso_model, s = cv_lasso$lambda.min, newx = x_train)
r_squared_lasso <- 1 - sum((y_train - lasso_pred)^2) / sum((y_train - mean(y_train))^2)
print(paste("R-squared for Lasso: ", r_squared_lasso))
```


```{r}
test <- lm(revenue_all ~ emp+spend_all+emp_incq1+emp_incq2+emp_incq3+emp_incq4+spend_aap+spend_acf+spend_aer+spend_apg+spend_durables+spend_nondurables+merchants_professional+merchants_health+merchants_food_accommodation+merchants_other_services+merchants_retail+NE+W+S+wave1, data=emp_aff_math_biz_clean)
summary(test)
```

```{r}
vif(test)
```




